# practical-llm
Practical LLM Dev


## Yesterday 
Transformer on CPU: https://colab.research.google.com/github/DJCordhose/practical-llm/blob/main/Assessment_SetFit.ipynb

* https://arxiv.org/pdf/2209.11055
* https://sbert.net/
* https://huggingface.co/blog/setfit

## Today
* small LLM on widely available and affordable GPU Quantized on T4 (16 GB): https://colab.research.google.com/github/DJCordhose/practical-llm/blob/main/Assessment_Llama_3_8B_T4.ipynb
* Full resolution on L4 (24 GB), fast and sensible, but you have to pay up: https://colab.research.google.com/github/DJCordhose/practical-llm/blob/main/Assessment_Llama_3_8B_L4.ipynb

## Future 
large LLM that really runs only on expensive hardware, preview only, please do not execute: https://colab.research.google.com/github/DJCordhose/practical-llm/blob/main/Assessment_Mixtral_8x7B.ipynb
