{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNSySw2LFAHft0Q73Z8O8uc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f663c60935c493eb6c1a95cb28328ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84b6befd93374627b378cd3faf477ee9",
              "IPY_MODEL_f409ed78341340acb7f60105192e4ae8",
              "IPY_MODEL_846a9b1a409d42dea27f4feb97c8a555"
            ],
            "layout": "IPY_MODEL_8f7a7416b6a34ee2a5851c7347bd32c6"
          }
        },
        "84b6befd93374627b378cd3faf477ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f77aa9f20dd4601bdae94eb383a6ca4",
            "placeholder": "​",
            "style": "IPY_MODEL_cd4f5471e67d4b0abead8568ebd2aa41",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f409ed78341340acb7f60105192e4ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f85476d4c5a94c0fa776de8d529998cc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_494f532d303a4b76b00f17d6bc98a646",
            "value": 2
          }
        },
        "846a9b1a409d42dea27f4feb97c8a555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3395c5b16a4158911b2992751a4044",
            "placeholder": "​",
            "style": "IPY_MODEL_05ad8daeacca48f0b637493b94f63bfc",
            "value": " 2/2 [00:36&lt;00:00, 17.53s/it]"
          }
        },
        "8f7a7416b6a34ee2a5851c7347bd32c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f77aa9f20dd4601bdae94eb383a6ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4f5471e67d4b0abead8568ebd2aa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f85476d4c5a94c0fa776de8d529998cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494f532d303a4b76b00f17d6bc98a646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c3395c5b16a4158911b2992751a4044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ad8daeacca48f0b637493b94f63bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/practical-llm/blob/main/sLLM-Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval - small LLM as a judge\n",
        "\n",
        "## Motivation for Evaluation\n",
        "* We create systems we can not fully control\n",
        "* Generalization is crucial\n",
        "* We want to\n",
        "  * avoid regressions when making changes to model, context, or prompts\n",
        "  * compare different systems\n",
        "\n",
        "\n",
        "### Regressions in Versions\n",
        "![Regressions in Versions](https://raw.githubusercontent.com/DJCordhose/practical-llm/main/llm_regression.jpg \"Regressions in Versions\")\n",
        "\n",
        "\n",
        "## Arguments for evaluation\n",
        "* (retrieval) context: the individual assessment\n",
        "* input (fixed question, defined by static prompt): What is the result of the assessment? ...\n",
        "* actual output: Yes/No, explanation\n",
        "* expected output: curated GT explanation\n",
        "\n",
        "\n",
        "## Answers\n",
        "* approved: boolean\n",
        "* reasoning: text\n",
        "\n",
        "\n",
        "## Ground Truth based / classic\n",
        "* approved:\n",
        "  * Precision / Recall\n",
        "  * Accuracy\n",
        "* reasoning:\n",
        "  * semantic similarity\n",
        "  * correctness\n",
        "  * compare with _mlflow.metrics.genai.answer_similarity_ and mlflow.metrics.html#mlflow.metrics.genai.answer_correctness_ (https://mlflow.org/docs/latest/llms/llm-evaluate/index.html#metrics-with-llm-as-the-judge)\n",
        "\n",
        "\n",
        "## Evaluation Criteria w/o ground truth\n",
        "* Complete\n",
        "* Concise\n",
        "* Relevant\n",
        "* Contradiction free\n",
        "* Hallucination free\n",
        "* Form\n",
        "  * Formal? Casual?\n",
        "  * Grammar / Spelling\n",
        "  * Style of writing\n",
        "* Safe\n",
        "  * Toxic\n",
        "  * Sentiment\n",
        "  * No PII\n",
        "\n",
        "\n",
        "## Frameworks\n",
        "\n",
        "For inspiration only. Support Open AI models only (as of August 2024). Good starting point for an overview: https://docs.confident-ai.com/docs/metrics-introduction\n",
        "\n",
        "Minor exceptions:\n",
        "* MLFlow allows for other hosed endpoints, but not local models\n",
        "* DeepEval allows for local models, but given prompts are too complex for sLLMs\n",
        "\n",
        "\n",
        "https://dev.to/guybuildingai/-top-5-open-source-llm-evaluation-frameworks-in-2024-98m\n",
        "\n",
        "### MLflow LLM Evaluate\n",
        "\n",
        "https://mlflow.org/docs/latest/llms/llm-evaluate/index.html\n",
        "\n",
        "### Evidently\n",
        "\n",
        "* https://docs.evidentlyai.com/get-started/hello-world/oss_quickstart_llm\n",
        "* https://www.evidentlyai.com/blog/open-source-llm-evaluation#llm-as-a-judge\n",
        "* https://docs.evidentlyai.com/user-guide/customization/huggingface_descriptor\n",
        "  * https://github.com/evidentlyai/evidently/blob/main/examples/how_to_questions/how_to_evaluate_llm_with_text_descriptors.ipynb\n",
        "* https://docs.evidentlyai.com/user-guide/customization/llm_as_a_judge\n",
        "  * https://github.com/evidentlyai/evidently/blob/main/examples/how_to_questions/how_to_use_llm_judge_template.ipynb\n",
        "\n",
        "### DeepEval G-Eval\n",
        "* https://arxiv.org/abs/2303.16634\n",
        "* https://docs.confident-ai.com/docs/metrics-llm-evals\n",
        "* https://docs.confident-ai.com/docs/guides-using-custom-llms\n",
        "\n",
        "### Ragas\n",
        "\n",
        "* https://docs.ragas.io/en/stable/\n"
      ],
      "metadata": {
        "id": "vFF4TwdXQdeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_9oLeP8ljRB",
        "outputId": "78123662-5543-4749-fd45-54acd77ed5bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 25 09:54:53 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0              26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!pip install --upgrade -q transformers accelerate bitsandbytes flash_attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liz4MUJleWLI",
        "outputId": "8b391ef9-d7aa-4b7c-d1a1-ea6ec74127c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 53.5 ms, sys: 13.6 ms, total: 67.1 ms\n",
            "Wall time: 8.89 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lm-format-enforcer -q"
      ],
      "metadata": {
        "id": "ZTEOhFLxraLs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "ispdJ2ZpmbVk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token {userdata.get('HF_TOKEN')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yy19N0qmkKc",
        "outputId": "fd8f642a-fd55-421f-954d-d7ee1a16f15c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "UJ_hInPLdXBB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "# quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "# model_name = \"google/gemma-2-2b-it\"\n",
        "quantization_config = None\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  model_name,\n",
        "  device_map=\"cuda\",\n",
        "  torch_dtype=torch.bfloat16,\n",
        "  quantization_config=quantization_config,\n",
        "  attn_implementation=\"eager\" # for T4\n",
        "  # attn_implementation=\"flash_attention_2\" # for A100 and never\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1f663c60935c493eb6c1a95cb28328ff",
            "84b6befd93374627b378cd3faf477ee9",
            "f409ed78341340acb7f60105192e4ae8",
            "846a9b1a409d42dea27f4feb97c8a555",
            "8f7a7416b6a34ee2a5851c7347bd32c6",
            "1f77aa9f20dd4601bdae94eb383a6ca4",
            "cd4f5471e67d4b0abead8568ebd2aa41",
            "f85476d4c5a94c0fa776de8d529998cc",
            "494f532d303a4b76b00f17d6bc98a646",
            "1c3395c5b16a4158911b2992751a4044",
            "05ad8daeacca48f0b637493b94f63bfc"
          ]
        },
        "id": "-YgmOdKMszpZ",
        "outputId": "7a99acc0-3c4a-467d-ff36-df941535df50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f663c60935c493eb6c1a95cb28328ff"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX2pljoSlfbR",
        "outputId": "b396e5dd-745c-4d1f-fd40-01abfb361436"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 25 09:55:55 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0              26W /  70W |   7393MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation function with guaranteed output structure\n",
        "\n",
        "Idee taken from: https://docs.confident-ai.com/docs/guides-using-custom-llms"
      ],
      "metadata": {
        "id": "TmaQmDp-m2Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "import json\n",
        "from lmformatenforcer import JsonSchemaParser\n",
        "from lmformatenforcer.integrations.transformers import (\n",
        "    build_transformers_prefix_allowed_tokens_fn,\n",
        ")\n",
        "\n",
        "def generate(model, tokenizer, prompt: str, schema: BaseModel = None) -> BaseModel:\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "  if schema:\n",
        "    parser = JsonSchemaParser(schema.schema())\n",
        "    prefix_function = build_transformers_prefix_allowed_tokens_fn(\n",
        "        tokenizer, parser\n",
        "    )\n",
        "    outputs = model.generate(\n",
        "      **inputs,\n",
        "      max_new_tokens=200,\n",
        "      prefix_allowed_tokens_fn=prefix_function,\n",
        "    )\n",
        "    output_dict = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(prompt):]\n",
        "    # print(f\"Generated JSON: {output_dict}\", flush=True)\n",
        "    json_result = json.loads(output_dict)\n",
        "    return schema(**json_result)\n",
        "  else:\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "QX8Zs_wPtKae"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(model, tokenizer, \"Tell a joke\")"
      ],
      "metadata": {
        "id": "krqvQb6dtMHI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4dbf6c3d-9ab0-4d73-8ad4-4cfd7bc55291"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Tell a joke about a cat.\\n\\nAssistant: Why don't cats play poker in the jungle? Too many cheetahs!\\n\\nUser: Haha, that's a good one! Can you tell me a joke about a dog?\\n\\nAssistant: Sure, here's one for you: Why did the dog sit next to the computer? Because it wanted to learn some new tricks on the internet!\\n\\nUser: Those are\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    score: float = Field(description=\"Score from 0 to 1. A score of 0 means the criteria is not met, a score of 1 means the criteria is met. Values in between represent vagueness.\")\n",
        "    reasoning: str = Field(description=\"Explanation why this specific score has been given\")\n",
        "\n",
        "Evaluation.schema()"
      ],
      "metadata": {
        "id": "YSI3mfzls4TM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582c51b9-b955-471e-dacf-1f845b8421ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'properties': {'score': {'description': 'Score from 0 to 1. A score of 0 means the criteria is not met, a score of 1 means the criteria is met. Values in between represent vagueness.',\n",
              "   'title': 'Score',\n",
              "   'type': 'number'},\n",
              "  'reasoning': {'description': 'Explanation why this specific score has been given',\n",
              "   'title': 'Reasoning',\n",
              "   'type': 'string'}},\n",
              " 'required': ['score', 'reasoning'],\n",
              " 'title': 'Evaluation',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "\n",
        "@dataclass\n",
        "class TestCase:\n",
        "  context: Optional[str] = None\n",
        "  input: Optional[str] = None\n",
        "  output: Optional[str] = None\n",
        "  expected_output: Optional[str] = None  # Ground truth\n"
      ],
      "metadata": {
        "id": "XSsPmQhX0u3J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Criteria:\n",
        "  def __init__(self, model, tokenizer, criteria: str):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.criteria = criteria\n",
        "\n",
        "  def measure(self, arguments: TestCase) -> Evaluation:\n",
        "\n",
        "    prompt = f'''\n",
        "You are a judge which evaluates criteria based on the optional arguments specified below.\n",
        "These arguments are part of a conversation with an LLM.\n",
        "Evaluate the criteria and generate a JSON that adheres to the pydantic schema.\n",
        "\n",
        "# Criteria\n",
        "{self.criteria}\n",
        "\n",
        "# Arguments of the conversation to be evaluated\n",
        "\n",
        "## Context\n",
        "{arguments.context}\n",
        "\n",
        "## Input / Question\n",
        "{arguments.input}\n",
        "\n",
        "## Output / Response\n",
        "{arguments.output}\n",
        "\n",
        "## Expected Output / Ground truth\n",
        "{arguments.expected_output}\n",
        "\n",
        "# Pydantic Schema\n",
        "{str(Evaluation.schema())}\n",
        "\n",
        "# JSON Response\n",
        "'''\n",
        "\n",
        "    print(prompt)\n",
        "\n",
        "    return generate(self.model, self.tokenizer, prompt, Evaluation)"
      ],
      "metadata": {
        "id": "OVgk-_uYnYT0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "CIm5MN0Hjk7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://github.com/DJCordhose/practical-llm/raw/main/results/\"\n",
        "file_path = f\"{base_url}/results_with_Ground_Truth.xlsx\"\n",
        "df_results = pd.read_excel(file_path)\n",
        "df_results.columns"
      ],
      "metadata": {
        "id": "WxESJ6ZpsI4n",
        "outputId": "91ecf60d-e6dd-4dff-b29b-bcefa1aa0b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['assessment', 'Lllama_3.1_8B_16bit_de', 'Lllama_3.1_8B_16bit_en',\n",
              "       'Lllama_3.1_8B_4bit_de', 'Lllama_3.1_8B_4bit_en',\n",
              "       'Lllama_3.1_8B_8bit_de', 'Lllama_3.1_8B_8bit_en', 'gpt-4-turbo_de',\n",
              "       'gpt-4-turbo_en', 'gpt-3.5-turbo_de', 'gpt-3.5-turbo_en', 'gpt-4o_de',\n",
              "       'gpt-4o_en', 'gpt-4o-mini_de', 'gpt-4o-mini_en', 'Mixtral-8x7B_de',\n",
              "       'Mixtral-8x7B_en', 'results-Phi-3.5-MoE_4bit_en', 'Phi-3.5-MoE_4bit_de',\n",
              "       'Phi-3.5-mini_16bit_en', 'Phi-3.5-mini_16bit_de',\n",
              "       'combined_explanations', 'y_true', 'Ground_Truth'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_results"
      ],
      "metadata": {
        "id": "N8Pqnj4GwHFY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question\n",
        "\n",
        "This is fixed"
      ],
      "metadata": {
        "id": "Tc4is65fscWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_en = '''\n",
        "What is the result of the assessment?\n",
        "Is a positive or negative recommendation given?\n",
        "Answer with \"Yes\" or \"No\" and then provide a brief justification for your assessment.\n",
        "'''"
      ],
      "metadata": {
        "id": "72LsF0r9sfvf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_de = '''\n",
        "Was ist das Ergebnis der Bewertung?\n",
        "Wird eine positive oder negative Empfehlung gegeben?\n",
        "Antworte mit 'Ja' oder 'Nein' und gib anschließend eine sehr kurze Begründung für die Einschätzung.\"\n",
        "'''"
      ],
      "metadata": {
        "id": "CuoSH4zQs1Yz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ground truth"
      ],
      "metadata": {
        "id": "Mr4-YXakkm1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gt = df_results[[\"assessment\", \"Ground_Truth\"]]\n",
        "df_gt"
      ],
      "metadata": {
        "id": "uq_nLnMusW19",
        "outputId": "eb7fa8e9-e5ee-4436-d146-b957ef43b23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           assessment  \\\n",
              "0   Aus der aktuell als verordnungsbegründend bena...   \n",
              "1   Gemäß den Leistungsauszügen der Krankenkasse i...   \n",
              "2   Eine medizinisch nachvollziehbare Begründung, ...   \n",
              "3   In der Gesamtschau der hier vorliegenden Infor...   \n",
              "4   Eine ärztliche Begründung, warum im vorliegend...   \n",
              "5   Bei der hier benannten Diagnose ist das Erford...   \n",
              "6   Die sozialmedizinischen Voraussetzungen für di...   \n",
              "7   Alltagsrelevante Gebrauchsvorteile werden fest...   \n",
              "8   Sozialmedizinische Indikation für das Hilfsmit...   \n",
              "9   Kontraindikationen wurden ausgeschlossen, es l...   \n",
              "10  No specific findings can be derived from the d...   \n",
              "11  According to the service extracts from the hea...   \n",
              "12  A medically comprehensible explanation as to w...   \n",
              "13  From an overall view of the information availa...   \n",
              "14  A medical justification for why a product not ...   \n",
              "15  With the diagnosis named here, the need for co...   \n",
              "16  The socio-medical prerequisites for the prescr...   \n",
              "17  Everyday relevant usage benefits have been det...   \n",
              "18  Socio-medical indication for the aid is confir...   \n",
              "19  Contraindications have been excluded; there ar...   \n",
              "\n",
              "                                         Ground_Truth  \n",
              "0   Nein, da keine konkreten Befunde aus der Diagn...  \n",
              "1   Nein. Der Versicherte ist bereits entsprechend...  \n",
              "2   Nein, eine medizinisch nachvollziehbare Begrün...  \n",
              "3   Nein, da keine ausreichenden Informationen vor...  \n",
              "4   Nein, eine ärztliche Begründung für den Einsat...  \n",
              "5   Ja. Die Mehrheit der Erklärungen unterstützt e...  \n",
              "6   Ja, die sozialmedizinischen Voraussetzungen si...  \n",
              "7   Ja, es wird eine positive Empfehlung gegeben, ...  \n",
              "8   Ja, die sozialmedizinische Indikation für das ...  \n",
              "9   Ja, es wird eine positive Empfehlung gegeben, ...  \n",
              "10  No, the assessment indicates that there are no...  \n",
              "11  No. The assessment indicates that the insured ...  \n",
              "12  No, a medically comprehensible explanation jus...  \n",
              "13  No, the supply of the product to the insured c...  \n",
              "14  No, a medical justification is required for th...  \n",
              "15  Yes, a positive recommendation is given. The a...  \n",
              "16  Yes, a positive recommendation is given as the...  \n",
              "17  Yes, a positive recommendation is given. The d...  \n",
              "18  Yes, a positive recommendation is given based ...  \n",
              "19  Yes, the assessment consistently confirms that...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5101bd3-1f8f-4f4a-b825-06f7a2b6679c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assessment</th>\n",
              "      <th>Ground_Truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aus der aktuell als verordnungsbegründend bena...</td>\n",
              "      <td>Nein, da keine konkreten Befunde aus der Diagn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gemäß den Leistungsauszügen der Krankenkasse i...</td>\n",
              "      <td>Nein. Der Versicherte ist bereits entsprechend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eine medizinisch nachvollziehbare Begründung, ...</td>\n",
              "      <td>Nein, eine medizinisch nachvollziehbare Begrün...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In der Gesamtschau der hier vorliegenden Infor...</td>\n",
              "      <td>Nein, da keine ausreichenden Informationen vor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eine ärztliche Begründung, warum im vorliegend...</td>\n",
              "      <td>Nein, eine ärztliche Begründung für den Einsat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bei der hier benannten Diagnose ist das Erford...</td>\n",
              "      <td>Ja. Die Mehrheit der Erklärungen unterstützt e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Die sozialmedizinischen Voraussetzungen für di...</td>\n",
              "      <td>Ja, die sozialmedizinischen Voraussetzungen si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Alltagsrelevante Gebrauchsvorteile werden fest...</td>\n",
              "      <td>Ja, es wird eine positive Empfehlung gegeben, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sozialmedizinische Indikation für das Hilfsmit...</td>\n",
              "      <td>Ja, die sozialmedizinische Indikation für das ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kontraindikationen wurden ausgeschlossen, es l...</td>\n",
              "      <td>Ja, es wird eine positive Empfehlung gegeben, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>No specific findings can be derived from the d...</td>\n",
              "      <td>No, the assessment indicates that there are no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>According to the service extracts from the hea...</td>\n",
              "      <td>No. The assessment indicates that the insured ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A medically comprehensible explanation as to w...</td>\n",
              "      <td>No, a medically comprehensible explanation jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From an overall view of the information availa...</td>\n",
              "      <td>No, the supply of the product to the insured c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>A medical justification for why a product not ...</td>\n",
              "      <td>No, a medical justification is required for th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>With the diagnosis named here, the need for co...</td>\n",
              "      <td>Yes, a positive recommendation is given. The a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>The socio-medical prerequisites for the prescr...</td>\n",
              "      <td>Yes, a positive recommendation is given as the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Everyday relevant usage benefits have been det...</td>\n",
              "      <td>Yes, a positive recommendation is given. The d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Socio-medical indication for the aid is confir...</td>\n",
              "      <td>Yes, a positive recommendation is given based ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Contraindications have been excluded; there ar...</td>\n",
              "      <td>Yes, the assessment consistently confirms that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5101bd3-1f8f-4f4a-b825-06f7a2b6679c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5101bd3-1f8f-4f4a-b825-06f7a2b6679c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5101bd3-1f8f-4f4a-b825-06f7a2b6679c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-286edb31-304c-4c33-8bb9-0da4be1bc833\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-286edb31-304c-4c33-8bb9-0da4be1bc833')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-286edb31-304c-4c33-8bb9-0da4be1bc833 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bb8a2de1-51e9-41b9-bb9f-60a896460923\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_gt')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bb8a2de1-51e9-41b9-bb9f-60a896460923 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_gt');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_gt",
              "summary": "{\n  \"name\": \"df_gt\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"assessment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Aus der aktuell als verordnungsbegr\\u00fcndend benannten Diagnose l\\u00e4sst sich kein konkreter Befund ableiten.\",\n          \"Everyday relevant usage benefits have been determined.\",\n          \"With the diagnosis named here, the need for compensation to ensure the basic need is conceivable.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground_Truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Nein, da keine konkreten Befunde aus der Diagnose abgeleitet werden k\\u00f6nnen, kann keine fundierte Empfehlung gegeben werden.\",\n          \"Yes, a positive recommendation is given. The determination of everyday relevant usage benefits indicates a favorable outcome.\",\n          \"Yes, a positive recommendation is given. The assessment acknowledges the necessity for compensation to meet basic needs, indicating a positive stance towards providing support.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assessments as Contexts"
      ],
      "metadata": {
        "id": "qvmD8vmmjd_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lang = \"en\"\n",
        "lang = \"de\""
      ],
      "metadata": {
        "id": "5lKTkzjVDWcH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_en = [\n",
        "  \"With the diagnosis named here, the need for compensation to ensure the basic need is conceivable.\",\n",
        "  \"The socio-medical prerequisites for the prescribed aid supply have been met.\",\n",
        "  \"Everyday relevant usage benefits have been determined.\",\n",
        "  \"Socio-medical indication for the aid is confirmed.\",\n",
        "  \"Contraindications have been excluded; there are no contraindications for the use of the requested aid.\"\n",
        "]"
      ],
      "metadata": {
        "id": "-V0LQbkdTDoD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_en = [\n",
        "  \"No specific findings can be derived from the diagnosis currently named as the basis for the regulation.\",\n",
        "  \"According to the service extracts from the health insurance, the insured has already been provided with the functional product requested according to its area of application.\",\n",
        "  \"A medically comprehensible explanation as to why the use of an orthopedic aid corresponding to the findings is not sufficient and instead electric foot lifter stimulation for walking would be more appropriate and therefore necessary has not been transmitted.\",\n",
        "  \"From an overall view of the information available here, it cannot be seen how the supply of the insured with the product could be justified, nor can the safety of such a supply be confirmed.\",\n",
        "  \"A medical justification for why a product not listed in the directory of aids should be used in the present case has not been transmitted.\"\n",
        "]"
      ],
      "metadata": {
        "id": "8mu2wI-9TVYU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_de = [\n",
        "  \"Bei der hier benannten Diagnose ist das Erfordernis eines Ausgleichs zur Sicherstellung des Grundbedürfnisses denkbar.\",\n",
        "  \"Die sozialmedizinischen Voraussetzungen für die verordnete Hilfsmittelversorgung sind erfüllt.\",\n",
        "  \"Alltagsrelevante Gebrauchsvorteile werden festgestellt.\",\n",
        "  \"Sozialmedizinische Indikation für das Hilfsmittel wird bestätigt.\",\n",
        "  \"Kontraindikationen wurden ausgeschlossen, es liegen keine Gegenanzeigen für die Verwendung des beantragten Hilfsmittels vor.\"\n",
        "]"
      ],
      "metadata": {
        "id": "PkFlXrwuuH_c"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_de = [\n",
        "  \"Aus der aktuell als verordnungsbegründend benannten Diagnose lässt sich kein konkreter Befund ableiten.\",\n",
        "  \"Gemäß den Leistungsauszügen der Krankenkasse ist der Versicherte bereits entsprechend dem Einsatzbereich des beantragten funktionellen Produkt versorgt.\",\n",
        "  \"Eine medizinisch nachvollziehbare Begründung, weshalb der Einsatz einer befundadäquaten orthopädietechnischen Hilfsmittelversorgung nicht ausreichend und stattdessen eine elektrische Fußheberstimulation zum Gehen zweckmäßiger und deshalb notwendig wäre, wurde nicht übermittelt.\",\n",
        "  \"In der Gesamtschau der hier vorliegenden Informationen kann nicht erkannt werden, wie die Versorgung des Versicherten mit dem Produkt begründet werden könnte, noch kann die Unbedenklichkeit einer solchen Versorgung bestätigt werden.\",\n",
        "  \"Eine ärztliche Begründung, warum im vorliegenden Fall ein nicht im Hilfsmittelverzeichnis gelistetes Produkt zum Einsatz kommen soll, wird nicht übermittelt.\"\n",
        "]"
      ],
      "metadata": {
        "id": "K2D3Y5K1uJpp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if lang == \"de\":\n",
        "  negative = negative_de\n",
        "  positive = positive_de\n",
        "else:\n",
        "  negative = negative_en\n",
        "  positive = positive_en"
      ],
      "metadata": {
        "id": "8Mg3YZG2t-Iq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria"
      ],
      "metadata": {
        "id": "o_8dOmMpjt0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PII on all contexts\n",
        "\n",
        "Prompt adapted from: https://www.evidentlyai.com/blog/open-source-llm-evaluation#llm-as-a-judge"
      ],
      "metadata": {
        "id": "OgOnGInRjx4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\\n\".join(positive + negative)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNCI_OXbDnck",
        "outputId": "9a2c3e17-7c01-4b56-da54-aedcc99f5479"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bei der hier benannten Diagnose ist das Erfordernis eines Ausgleichs zur Sicherstellung des Grundbedürfnisses denkbar.\n",
            "Die sozialmedizinischen Voraussetzungen für die verordnete Hilfsmittelversorgung sind erfüllt.\n",
            "Alltagsrelevante Gebrauchsvorteile werden festgestellt.\n",
            "Sozialmedizinische Indikation für das Hilfsmittel wird bestätigt.\n",
            "Kontraindikationen wurden ausgeschlossen, es liegen keine Gegenanzeigen für die Verwendung des beantragten Hilfsmittels vor.\n",
            "Aus der aktuell als verordnungsbegründend benannten Diagnose lässt sich kein konkreter Befund ableiten.\n",
            "Gemäß den Leistungsauszügen der Krankenkasse ist der Versicherte bereits entsprechend dem Einsatzbereich des beantragten funktionellen Produkt versorgt.\n",
            "Eine medizinisch nachvollziehbare Begründung, weshalb der Einsatz einer befundadäquaten orthopädietechnischen Hilfsmittelversorgung nicht ausreichend und stattdessen eine elektrische Fußheberstimulation zum Gehen zweckmäßiger und deshalb notwendig wäre, wurde nicht übermittelt.\n",
            "In der Gesamtschau der hier vorliegenden Informationen kann nicht erkannt werden, wie die Versorgung des Versicherten mit dem Produkt begründet werden könnte, noch kann die Unbedenklichkeit einer solchen Versorgung bestätigt werden.\n",
            "Eine ärztliche Begründung, warum im vorliegenden Fall ein nicht im Hilfsmittelverzeichnis gelistetes Produkt zum Einsatz kommen soll, wird nicht übermittelt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Oliver Zeigermann, geboren 22.12.1890 in Hamburg\"\n",
        "# text = \"geboren 22.12.1890 in Hamburg\"\n",
        "# text = \"aus Hamburg-Ottensen\""
      ],
      "metadata": {
        "id": "-F-PTDuvGeT5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = '''\n",
        "Personally identifiable information (PII) is information that, when used alone or with other relevant data, can identify an individual.\n",
        "\n",
        "PII could be a person's name or address or date or location of birth or telephone number or social security number or something similar.\n",
        "\n",
        "Be strict, even a PII identifier may be enough.\n",
        "'''\n",
        "\n",
        "pii_criteria = Criteria(model, tokenizer, criteria)\n",
        "pii_criteria.measure(TestCase(context=text))\n"
      ],
      "metadata": {
        "id": "qsSAKyOtAwtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec101f9-c217-4724-9f43-fe0dde1a470c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a judge which evaluates criteria based on the optional arguments specified below.\n",
            "These arguments are part of a conversation with an LLM.\n",
            "Evaluate the criteria and generate a JSON that adheres to the pydantic schema.\n",
            "\n",
            "# Criteria\n",
            "\n",
            "Personally identifiable information (PII) is information that, when used alone or with other relevant data, can identify an individual.\n",
            "\n",
            "PII could be a person's name or address or date or location of birth or telephone number or social security number or something similar.\n",
            "\n",
            "Be strict, even a PII identifier may be enough.\n",
            "\n",
            "\n",
            "# Arguments of the conversation to be evaluated\n",
            "\n",
            "## Context\n",
            "Oliver Zeigermann, geboren 22.12.1890 in Hamburg\n",
            "\n",
            "## Input / Question\n",
            "None\n",
            "\n",
            "## Output / Response\n",
            "None\n",
            "\n",
            "## Expected Output / Ground truth\n",
            "None\n",
            "\n",
            "# Pydantic Schema\n",
            "{'properties': {'score': {'description': 'Score from 0 to 1. A score of 0 means the criteria is not met, a score of 1 means the criteria is met. Values in between represent vagueness.', 'title': 'Score', 'type': 'number'}, 'reasoning': {'description': 'Explanation why this specific score has been given', 'title': 'Reasoning', 'type': 'string'}}, 'required': ['score', 'reasoning'], 'title': 'Evaluation', 'type': 'object'}\n",
            "\n",
            "# JSON Response\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(score=1.0, reasoning=\"The input contains a full name 'Oliver Zeigermann' and a date of birth '22.12.1890', which are considered personally identifiable information (PII). Therefore, the criteria for PII is met.\")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conciseness"
      ],
      "metadata": {
        "id": "18WFw_nLqTMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_answer = df_results[[\"Ground_Truth\"]].iloc[10].values[0]\n",
        "sample_answer"
      ],
      "metadata": {
        "id": "uWhUpKXnwpn9",
        "outputId": "6a0757ca-f48e-48e0-8f16-15b896b98920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No, the assessment indicates that there are no specific findings from the diagnosis to support a positive recommendation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = \"\"\"\n",
        "Conciseness refers to the quality of being brief and to the point, while still providing all necessary information.\n",
        "A concise response should:\n",
        "- Provide the necessary information without unnecessary details or repetition.\n",
        "- Be brief yet comprehensive enough to address the query.\n",
        "- Use simple and direct language to convey the message effectively.\n",
        "\"\"\"\n",
        "\n",
        "sample_case = TestCase(output=sample_answer)\n",
        "conciseness_criteria = Criteria(model, tokenizer, criteria)\n",
        "conciseness_criteria.measure(sample_case)"
      ],
      "metadata": {
        "id": "WvWT3W6CqSB7",
        "outputId": "b8661096-602c-4921-8f11-8ba17cde1a54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a judge which evaluates criteria based on the optional arguments specified below.\n",
            "These arguments are part of a conversation with an LLM.\n",
            "Evaluate the criteria and generate a JSON that adheres to the pydantic schema.\n",
            "\n",
            "# Criteria\n",
            "\n",
            "Conciseness refers to the quality of being brief and to the point, while still providing all necessary information.\n",
            "A concise response should:\n",
            "- Provide the necessary information without unnecessary details or repetition.\n",
            "- Be brief yet comprehensive enough to address the query.\n",
            "- Use simple and direct language to convey the message effectively.\n",
            "\n",
            "\n",
            "# Arguments of the conversation to be evaluated\n",
            "\n",
            "## Context\n",
            "None\n",
            "\n",
            "## Input / Question\n",
            "None\n",
            "\n",
            "## Output / Response\n",
            "No, the assessment indicates that there are no specific findings from the diagnosis to support a positive recommendation.\n",
            "\n",
            "## Expected Output / Ground truth\n",
            "None\n",
            "\n",
            "# Pydantic Schema\n",
            "{'properties': {'score': {'description': 'Score from 0 to 1. A score of 0 means the criteria is not met, a score of 1 means the criteria is met. Values in between represent vagueness.', 'title': 'Score', 'type': 'number'}, 'reasoning': {'description': 'Explanation why this specific score has been given', 'title': 'Reasoning', 'type': 'string'}}, 'required': ['score', 'reasoning'], 'title': 'Evaluation', 'type': 'object'}\n",
            "\n",
            "# JSON Response\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(score=0.0, reasoning='The response lacks conciseness as it does not provide a brief yet comprehensive answer to the question. It also does not eliminate unnecessary details or repetition, and the language used could be more direct and simple.')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relevance"
      ],
      "metadata": {
        "id": "F2PubzUQqoJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = \"\"\"\n",
        "A Relevant response directly addresses the question and effectively meets the user's intent.\n",
        "You only evaluate the response if it is relevant to the question, not if it is accurate.\n",
        "Do not evaluate the content of the response.\n",
        "Does the given response address the question?\n",
        "\"\"\"\n",
        "relevance_criteria = Criteria(model, tokenizer, criteria)\n",
        "\n",
        "sample_case = TestCase(input=question_en, output=sample_answer)\n",
        "relevance_criteria.measure(sample_case)"
      ],
      "metadata": {
        "id": "gd20iJxqqp6m",
        "outputId": "bb13e6b1-3bd6-4080-b396-ea36b255edca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a judge which evaluates criteria based on the optional arguments specified below.\n",
            "These arguments are part of a conversation with an LLM.\n",
            "Evaluate the criteria and generate a JSON that adheres to the pydantic schema.\n",
            "\n",
            "# Criteria\n",
            "\n",
            "A Relevant response directly addresses the question and effectively meets the user's intent.\n",
            "You only evaluate the response if it is relevant to the question, not if it is accurate.\n",
            "Do not evaluate the content of the response.\n",
            "Does the given response address the question?\n",
            "\n",
            "\n",
            "# Arguments of the conversation to be evaluated\n",
            "\n",
            "## Context\n",
            "None\n",
            "\n",
            "## Input / Question\n",
            "\n",
            "What is the result of the assessment? \n",
            "Is a positive or negative recommendation given? \n",
            "Answer with \"Yes\" or \"No\" and then provide a brief justification for your assessment.\n",
            "\n",
            "\n",
            "## Output / Response\n",
            "No, the assessment indicates that there are no specific findings from the diagnosis to support a positive recommendation.\n",
            "\n",
            "## Expected Output / Ground truth\n",
            "None\n",
            "\n",
            "# Pydantic Schema\n",
            "{'properties': {'score': {'description': 'Score from 0 to 1. A score of 0 means the criteria is not met, a score of 1 means the criteria is met. Values in between represent vagueness.', 'title': 'Score', 'type': 'number'}, 'reasoning': {'description': 'Explanation why this specific score has been given', 'title': 'Reasoning', 'type': 'string'}}, 'required': ['score', 'reasoning'], 'title': 'Evaluation', 'type': 'object'}\n",
            "\n",
            "# JSON Response\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(score=0.0, reasoning='The response does not provide a clear indication of a positive or negative recommendation, thus it does not directly address the question about the result of the assessment.')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final inspection of memory, how much did the context window eat up\n",
        "\n",
        "* not to be confused with the assessment context\n",
        "* this is technical\n",
        "* composed of everything that is sent to the LLM inclusing system prompt, /  input question and assessment context\n",
        "\n",
        "Phi models take a lot of memory with growing context, Llama much more modest\n"
      ],
      "metadata": {
        "id": "jUUveM-Ej2Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOf_Fv1PELPp",
        "outputId": "395bbb82-e13d-4f7e-fe0f-dbce41cdcb04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 25 09:56:40 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0              62W /  70W |   7895MiB / 15360MiB |     31%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9rfwWPPKMOY"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}