{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkKJIRlcWZwy2VkabmQuLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97e81ff16cd44b12a1b4b53e05e2132d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca8d2163ab724cd996bcde3278bc9b36",
              "IPY_MODEL_045c7edf3a4a464ba4e7eaabda1c9aa9",
              "IPY_MODEL_dcf9b715762942bfb815da86761307e6"
            ],
            "layout": "IPY_MODEL_c5238708930c4c81905acafb5aca9d3c"
          }
        },
        "ca8d2163ab724cd996bcde3278bc9b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f878d633194c1e824386a49c4cb78a",
            "placeholder": "​",
            "style": "IPY_MODEL_5074487840004da4b43de35bd33ffffe",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "045c7edf3a4a464ba4e7eaabda1c9aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4645138d55d448ca35eeba63f974157",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_361b195a364b48d783d30731b53ecd7a",
            "value": 2
          }
        },
        "dcf9b715762942bfb815da86761307e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adfb00d457a349b9b9a389eba71b9c0b",
            "placeholder": "​",
            "style": "IPY_MODEL_a3a39791c7f64989a837af837500c11d",
            "value": " 2/2 [00:36&lt;00:00, 17.22s/it]"
          }
        },
        "c5238708930c4c81905acafb5aca9d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f878d633194c1e824386a49c4cb78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5074487840004da4b43de35bd33ffffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4645138d55d448ca35eeba63f974157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361b195a364b48d783d30731b53ecd7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adfb00d457a349b9b9a389eba71b9c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a39791c7f64989a837af837500c11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/practical-llm/blob/main/sLLM-Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval - small LLM as a judge\n",
        "\n",
        "## Motivation for Evaluation\n",
        "* We create systems we can not fully control\n",
        "* Generalization is crucial\n",
        "* We want to\n",
        "  * avoid regressions when making changes to model, context, or prompts\n",
        "  * compare different systems\n",
        "\n",
        "\n",
        "### Regressions in Versions\n",
        "![Regressions in Versions](https://raw.githubusercontent.com/DJCordhose/practical-llm/main/llm_regression.jpg \"Regressions in Versions\")\n",
        "\n",
        "\n",
        "## Arguments for evaluation\n",
        "* (retrieval) context: the individual assessment\n",
        "* input (fixed question, defined by static prompt): What is the result of the assessment? ...\n",
        "* actual output: Yes/No, explanation\n",
        "* expected output: curated GT explanation\n",
        "\n",
        "\n",
        "## Answers\n",
        "* approved: boolean\n",
        "* reasoning: text\n",
        "\n",
        "\n",
        "## Ground Truth based / classic\n",
        "* approved:\n",
        "  * Precision / Recall\n",
        "  * Accuracy\n",
        "* reasoning:\n",
        "  * semantic similarity\n",
        "  * correctness\n",
        "  * compare with _mlflow.metrics.genai.answer_similarity_ and mlflow.metrics.html#mlflow.metrics.genai.answer_correctness_ (https://mlflow.org/docs/latest/llms/llm-evaluate/index.html#metrics-with-llm-as-the-judge)\n",
        "\n",
        "\n",
        "## Evaluation Criteria w/o ground truth\n",
        "* Complete\n",
        "* Concise\n",
        "* Relevant\n",
        "* Contradiction free\n",
        "* Hallucination free\n",
        "* Form\n",
        "  * Formal? Casual?\n",
        "  * Grammar / Spelling\n",
        "  * Style of writing\n",
        "* Safe\n",
        "  * Toxic\n",
        "  * Sentiment\n",
        "  * No PII\n",
        "\n",
        "\n",
        "## Frameworks\n",
        "\n",
        "For inspiration only. Support Open AI models only (as of August 2024). Good starting point for an overview: https://docs.confident-ai.com/docs/metrics-introduction\n",
        "\n",
        "Minor exceptions:\n",
        "* MLFlow allows for other hosed endpoints, but not local models\n",
        "* DeepEval allows for local models, but given prompts are too complex for sLLMs\n",
        "\n",
        "\n",
        "https://dev.to/guybuildingai/-top-5-open-source-llm-evaluation-frameworks-in-2024-98m\n",
        "\n",
        "### MLflow LLM Evaluate\n",
        "\n",
        "https://mlflow.org/docs/latest/llms/llm-evaluate/index.html\n",
        "\n",
        "### Evidently\n",
        "\n",
        "* https://docs.evidentlyai.com/get-started/hello-world/oss_quickstart_llm\n",
        "* https://www.evidentlyai.com/blog/open-source-llm-evaluation#llm-as-a-judge\n",
        "* https://docs.evidentlyai.com/user-guide/customization/huggingface_descriptor\n",
        "  * https://github.com/evidentlyai/evidently/blob/main/examples/how_to_questions/how_to_evaluate_llm_with_text_descriptors.ipynb\n",
        "* https://docs.evidentlyai.com/user-guide/customization/llm_as_a_judge\n",
        "  * https://github.com/evidentlyai/evidently/blob/main/examples/how_to_questions/how_to_use_llm_judge_template.ipynb\n",
        "\n",
        "### DeepEval G-Eval\n",
        "* https://arxiv.org/abs/2303.16634\n",
        "* https://docs.confident-ai.com/docs/metrics-llm-evals\n",
        "* https://docs.confident-ai.com/docs/guides-using-custom-llms\n",
        "\n",
        "### Ragas\n",
        "\n",
        "* https://docs.ragas.io/en/stable/\n"
      ],
      "metadata": {
        "id": "vFF4TwdXQdeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-On\n",
        "\n",
        "Prompting for smaller LLMs is even harder than for the powerful ones. These prompts need to generalize beyond a single example.\n",
        "\n",
        "Add an additional Criteria Rule for one the criteria named above and at it to the test suite. Alternatively try to improve on one of the existing criteria."
      ],
      "metadata": {
        "id": "jO93wLSFWwHb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ERArfxLXWvcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_9oLeP8ljRB",
        "outputId": "bab0a818-ef46-4a4e-ec85-78d61616d11c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 25 11:36:45 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0              30W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!pip install --upgrade -q transformers accelerate bitsandbytes flash_attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liz4MUJleWLI",
        "outputId": "bf421100-258b-4b58-efd3-f46f44b181e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 39 ms, sys: 7.63 ms, total: 46.6 ms\n",
            "Wall time: 5.85 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lm-format-enforcer -q"
      ],
      "metadata": {
        "id": "ZTEOhFLxraLs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "ispdJ2ZpmbVk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token {userdata.get('HF_TOKEN')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yy19N0qmkKc",
        "outputId": "0140f447-943d-451b-8ded-ead7385f1595"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "UJ_hInPLdXBB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "# quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "# model_name = \"google/gemma-2-2b-it\"\n",
        "quantization_config = None\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  model_name,\n",
        "  device_map=\"cuda\",\n",
        "  torch_dtype=torch.bfloat16,\n",
        "  quantization_config=quantization_config,\n",
        "  attn_implementation=\"eager\" # for T4\n",
        "  # attn_implementation=\"flash_attention_2\" # for A100 and never\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "97e81ff16cd44b12a1b4b53e05e2132d",
            "ca8d2163ab724cd996bcde3278bc9b36",
            "045c7edf3a4a464ba4e7eaabda1c9aa9",
            "dcf9b715762942bfb815da86761307e6",
            "c5238708930c4c81905acafb5aca9d3c",
            "f2f878d633194c1e824386a49c4cb78a",
            "5074487840004da4b43de35bd33ffffe",
            "e4645138d55d448ca35eeba63f974157",
            "361b195a364b48d783d30731b53ecd7a",
            "adfb00d457a349b9b9a389eba71b9c0b",
            "a3a39791c7f64989a837af837500c11d"
          ]
        },
        "id": "-YgmOdKMszpZ",
        "outputId": "cf9f7d7a-dc01-49fe-d3d6-2fcb420f8502"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97e81ff16cd44b12a1b4b53e05e2132d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX2pljoSlfbR",
        "outputId": "fdda25f2-d2ca-4573-ce6f-8b3788c98670"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 25 11:37:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0              29W /  70W |   7393MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation function with guaranteed output structure\n",
        "\n",
        "Idee taken from: https://docs.confident-ai.com/docs/guides-using-custom-llms"
      ],
      "metadata": {
        "id": "TmaQmDp-m2Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "import json\n",
        "from lmformatenforcer import JsonSchemaParser\n",
        "from lmformatenforcer.integrations.transformers import (\n",
        "    build_transformers_prefix_allowed_tokens_fn,\n",
        ")\n",
        "\n",
        "def generate(model, tokenizer, prompt: str, schema: BaseModel = None) -> BaseModel:\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "  if schema:\n",
        "    parser = JsonSchemaParser(schema.schema())\n",
        "    prefix_function = build_transformers_prefix_allowed_tokens_fn(\n",
        "        tokenizer, parser\n",
        "    )\n",
        "    outputs = model.generate(\n",
        "      **inputs,\n",
        "      max_new_tokens=200,\n",
        "      prefix_allowed_tokens_fn=prefix_function,\n",
        "    )\n",
        "    output_dict = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(prompt):]\n",
        "    # print(f\"Generated JSON: {output_dict}\", flush=True)\n",
        "    json_result = json.loads(output_dict)\n",
        "    return schema(**json_result)\n",
        "  else:\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "QX8Zs_wPtKae"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(model, tokenizer, \"Tell a joke\")"
      ],
      "metadata": {
        "id": "krqvQb6dtMHI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0f9fef53-098f-4fd6-ea69-519edbf70a24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Tell a joke about a cat.\\n\\nAssistant: Why don't cats play poker in the jungle? Too many cheetahs!\\n\\nUser: Haha, that's a good one! Can you tell me a joke about a dog?\\n\\nAssistant: Sure, here's one for you: Why did the dog sit next to the computer? Because it wanted to learn some new tricks on the internet!\\n\\nUser: Those are\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    name: str = Field(description=\"Name of the criteria.\")\n",
        "    score: float = Field(description=\"Score from 0 (not met) to 1 (met) as a float. All values in between are allowed and repesent vagueness.\")\n",
        "    reasoning: str = Field(description=\"Explanation why the criteria is met or not.\")\n",
        "\n",
        "Evaluation.schema()"
      ],
      "metadata": {
        "id": "YSI3mfzls4TM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e313f2fe-cc4a-491b-ea27-10835d8ff489"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'properties': {'name': {'description': 'Name of the criteria.',\n",
              "   'title': 'Name',\n",
              "   'type': 'string'},\n",
              "  'score': {'description': 'Score from 0 (not met) to 1 (met) as a float. All values in between are allowed and repesent vagueness.',\n",
              "   'title': 'Score',\n",
              "   'type': 'number'},\n",
              "  'reasoning': {'description': 'Explanation why the criteria is met or not.',\n",
              "   'title': 'Reasoning',\n",
              "   'type': 'string'}},\n",
              " 'required': ['name', 'score', 'reasoning'],\n",
              " 'title': 'Evaluation',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "\n",
        "@dataclass\n",
        "class TestCase:\n",
        "  context: Optional[str] = None\n",
        "  input: Optional[str] = None\n",
        "  output: Optional[str] = None\n",
        "  expected_output: Optional[str] = None  # Ground truth\n"
      ],
      "metadata": {
        "id": "XSsPmQhX0u3J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Criteria:\n",
        "  def __init__(self, name: str, criteria: str, model, tokenizer, is_negative: bool = False):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.criteria = criteria\n",
        "    self.name = name\n",
        "    self.is_negative = is_negative\n",
        "\n",
        "  def measure(self, arguments: TestCase) -> Evaluation:\n",
        "\n",
        "    prompt = f'''\n",
        "You are a judge evaluating criteria based on a conversation with an LLM.\n",
        "Evaluate the criteria and generate a JSON that adheres to the pydantic schema.\n",
        "In your response consistently stick to the language of the arguments, either English or German.\n",
        "\n",
        "# Name of Criteria\n",
        "{self.name}\n",
        "\n",
        "# Description of Criteria\n",
        "{self.criteria}\n",
        "\n",
        "# Optional arguments of the conversation to be evaluated\n",
        "\n",
        "## Context\n",
        "{arguments.context}\n",
        "\n",
        "## Input / Question / Query\n",
        "{arguments.input}\n",
        "\n",
        "## Output / Response / Answer\n",
        "{arguments.output}\n",
        "\n",
        "## Expected Output / Ground truth\n",
        "{arguments.expected_output}\n",
        "\n",
        "# Pydantic Schema\n",
        "{str(Evaluation.schema())}\n",
        "\n",
        "# Description of Criteria\n",
        "{self.criteria}\n",
        "\n",
        "# JSON Response\n",
        "'''\n",
        "\n",
        "    # print(prompt)\n",
        "\n",
        "    evaluation: Evaluation = generate(self.model, self.tokenizer, prompt, Evaluation)\n",
        "    if self.is_negative:\n",
        "      evaluation.score = 1.0 - evaluation.score\n",
        "    return evaluation"
      ],
      "metadata": {
        "id": "OVgk-_uYnYT0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "CIm5MN0Hjk7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://github.com/DJCordhose/practical-llm/raw/main/results/\"\n",
        "file_path = f\"{base_url}/results_with_Ground_Truth.xlsx\"\n",
        "df_results = pd.read_excel(file_path)\n",
        "df_results.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxESJ6ZpsI4n",
        "outputId": "544de65f-57c4-461f-90cf-2b6177f3079c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['assessment', 'Lllama_3.1_8B_16bit_de', 'Lllama_3.1_8B_16bit_en',\n",
              "       'Lllama_3.1_8B_4bit_de', 'Lllama_3.1_8B_4bit_en',\n",
              "       'Lllama_3.1_8B_8bit_de', 'Lllama_3.1_8B_8bit_en', 'gpt-4-turbo_de',\n",
              "       'gpt-4-turbo_en', 'gpt-3.5-turbo_de', 'gpt-3.5-turbo_en', 'gpt-4o_de',\n",
              "       'gpt-4o_en', 'gpt-4o-mini_de', 'gpt-4o-mini_en', 'Mixtral-8x7B_de',\n",
              "       'Mixtral-8x7B_en', 'results-Phi-3.5-MoE_4bit_en', 'Phi-3.5-MoE_4bit_de',\n",
              "       'Phi-3.5-mini_16bit_en', 'Phi-3.5-mini_16bit_de',\n",
              "       'combined_explanations', 'y_true', 'Ground_Truth'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_results"
      ],
      "metadata": {
        "id": "N8Pqnj4GwHFY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question\n",
        "\n",
        "This is fixed"
      ],
      "metadata": {
        "id": "Tc4is65fscWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_en = '''\n",
        "What is the result of the assessment?\n",
        "Is a positive or negative recommendation given?\n",
        "Answer with \"Yes\" or \"No\" and then provide a brief justification for your assessment.\n",
        "'''"
      ],
      "metadata": {
        "id": "72LsF0r9sfvf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_de = '''\n",
        "Was ist das Ergebnis der Bewertung?\n",
        "Wird eine positive oder negative Empfehlung gegeben?\n",
        "Antworte mit 'Ja' oder 'Nein' und gib anschließend eine sehr kurze Begründung für die Einschätzung.\"\n",
        "'''"
      ],
      "metadata": {
        "id": "CuoSH4zQs1Yz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ground truth"
      ],
      "metadata": {
        "id": "Mr4-YXakkm1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gt = df_results[[\"assessment\", \"Ground_Truth\"]]\n",
        "df_gt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "uq_nLnMusW19",
        "outputId": "a104ba0b-7a41-4fa9-b166-c6f753254875"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           assessment  \\\n",
              "0   Aus der aktuell als verordnungsbegründend bena...   \n",
              "1   Gemäß den Leistungsauszügen der Krankenkasse i...   \n",
              "2   Eine medizinisch nachvollziehbare Begründung, ...   \n",
              "3   In der Gesamtschau der hier vorliegenden Infor...   \n",
              "4   Eine ärztliche Begründung, warum im vorliegend...   \n",
              "5   Bei der hier benannten Diagnose ist das Erford...   \n",
              "6   Die sozialmedizinischen Voraussetzungen für di...   \n",
              "7   Alltagsrelevante Gebrauchsvorteile werden fest...   \n",
              "8   Sozialmedizinische Indikation für das Hilfsmit...   \n",
              "9   Kontraindikationen wurden ausgeschlossen, es l...   \n",
              "10  No specific findings can be derived from the d...   \n",
              "11  According to the service extracts from the hea...   \n",
              "12  A medically comprehensible explanation as to w...   \n",
              "13  From an overall view of the information availa...   \n",
              "14  A medical justification for why a product not ...   \n",
              "15  With the diagnosis named here, the need for co...   \n",
              "16  The socio-medical prerequisites for the prescr...   \n",
              "17  Everyday relevant usage benefits have been det...   \n",
              "18  Socio-medical indication for the aid is confir...   \n",
              "19  Contraindications have been excluded; there ar...   \n",
              "\n",
              "                                         Ground_Truth  \n",
              "0   Nein, da keine konkreten Befunde aus der Diagn...  \n",
              "1   Nein. Der Versicherte ist bereits entsprechend...  \n",
              "2   Nein, eine medizinisch nachvollziehbare Begrün...  \n",
              "3   Nein, da keine ausreichenden Informationen vor...  \n",
              "4   Nein, eine ärztliche Begründung für den Einsat...  \n",
              "5   Ja. Die Mehrheit der Erklärungen unterstützt e...  \n",
              "6   Ja, die sozialmedizinischen Voraussetzungen si...  \n",
              "7   Ja, es wird eine positive Empfehlung gegeben, ...  \n",
              "8   Ja, die sozialmedizinische Indikation für das ...  \n",
              "9   Ja, es wird eine positive Empfehlung gegeben, ...  \n",
              "10  No, the assessment indicates that there are no...  \n",
              "11  No. The assessment indicates that the insured ...  \n",
              "12  No, a medically comprehensible explanation jus...  \n",
              "13  No, the supply of the product to the insured c...  \n",
              "14  No, a medical justification is required for th...  \n",
              "15  Yes, a positive recommendation is given. The a...  \n",
              "16  Yes, a positive recommendation is given as the...  \n",
              "17  Yes, a positive recommendation is given. The d...  \n",
              "18  Yes, a positive recommendation is given based ...  \n",
              "19  Yes, the assessment consistently confirms that...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fac2e33c-87d8-4f36-a36f-3994acd396af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assessment</th>\n",
              "      <th>Ground_Truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aus der aktuell als verordnungsbegründend bena...</td>\n",
              "      <td>Nein, da keine konkreten Befunde aus der Diagn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gemäß den Leistungsauszügen der Krankenkasse i...</td>\n",
              "      <td>Nein. Der Versicherte ist bereits entsprechend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eine medizinisch nachvollziehbare Begründung, ...</td>\n",
              "      <td>Nein, eine medizinisch nachvollziehbare Begrün...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In der Gesamtschau der hier vorliegenden Infor...</td>\n",
              "      <td>Nein, da keine ausreichenden Informationen vor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eine ärztliche Begründung, warum im vorliegend...</td>\n",
              "      <td>Nein, eine ärztliche Begründung für den Einsat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bei der hier benannten Diagnose ist das Erford...</td>\n",
              "      <td>Ja. Die Mehrheit der Erklärungen unterstützt e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Die sozialmedizinischen Voraussetzungen für di...</td>\n",
              "      <td>Ja, die sozialmedizinischen Voraussetzungen si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Alltagsrelevante Gebrauchsvorteile werden fest...</td>\n",
              "      <td>Ja, es wird eine positive Empfehlung gegeben, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sozialmedizinische Indikation für das Hilfsmit...</td>\n",
              "      <td>Ja, die sozialmedizinische Indikation für das ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kontraindikationen wurden ausgeschlossen, es l...</td>\n",
              "      <td>Ja, es wird eine positive Empfehlung gegeben, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>No specific findings can be derived from the d...</td>\n",
              "      <td>No, the assessment indicates that there are no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>According to the service extracts from the hea...</td>\n",
              "      <td>No. The assessment indicates that the insured ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A medically comprehensible explanation as to w...</td>\n",
              "      <td>No, a medically comprehensible explanation jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From an overall view of the information availa...</td>\n",
              "      <td>No, the supply of the product to the insured c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>A medical justification for why a product not ...</td>\n",
              "      <td>No, a medical justification is required for th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>With the diagnosis named here, the need for co...</td>\n",
              "      <td>Yes, a positive recommendation is given. The a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>The socio-medical prerequisites for the prescr...</td>\n",
              "      <td>Yes, a positive recommendation is given as the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Everyday relevant usage benefits have been det...</td>\n",
              "      <td>Yes, a positive recommendation is given. The d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Socio-medical indication for the aid is confir...</td>\n",
              "      <td>Yes, a positive recommendation is given based ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Contraindications have been excluded; there ar...</td>\n",
              "      <td>Yes, the assessment consistently confirms that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fac2e33c-87d8-4f36-a36f-3994acd396af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fac2e33c-87d8-4f36-a36f-3994acd396af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fac2e33c-87d8-4f36-a36f-3994acd396af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1128356d-b9a4-4332-8126-84d4db5647f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1128356d-b9a4-4332-8126-84d4db5647f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1128356d-b9a4-4332-8126-84d4db5647f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6b5ba209-ede6-449b-b9e1-de7197240cd9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_gt')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b5ba209-ede6-449b-b9e1-de7197240cd9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_gt');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_gt",
              "summary": "{\n  \"name\": \"df_gt\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"assessment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Aus der aktuell als verordnungsbegr\\u00fcndend benannten Diagnose l\\u00e4sst sich kein konkreter Befund ableiten.\",\n          \"Everyday relevant usage benefits have been determined.\",\n          \"With the diagnosis named here, the need for compensation to ensure the basic need is conceivable.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground_Truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Nein, da keine konkreten Befunde aus der Diagnose abgeleitet werden k\\u00f6nnen, kann keine fundierte Empfehlung gegeben werden.\",\n          \"Yes, a positive recommendation is given. The determination of everyday relevant usage benefits indicates a favorable outcome.\",\n          \"Yes, a positive recommendation is given. The assessment acknowledges the necessity for compensation to meet basic needs, indicating a positive stance towards providing support.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assessments as Contexts"
      ],
      "metadata": {
        "id": "qvmD8vmmjd_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang = \"en\"\n",
        "# lang = \"de\""
      ],
      "metadata": {
        "id": "5lKTkzjVDWcH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_en = [\n",
        "  \"With the diagnosis named here, the need for compensation to ensure the basic need is conceivable.\",\n",
        "  \"The socio-medical prerequisites for the prescribed aid supply have been met.\",\n",
        "  \"Everyday relevant usage benefits have been determined.\",\n",
        "  \"Socio-medical indication for the aid is confirmed.\",\n",
        "  \"Contraindications have been excluded; there are no contraindications for the use of the requested aid.\"\n",
        "]"
      ],
      "metadata": {
        "id": "-V0LQbkdTDoD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_en = [\n",
        "  \"No specific findings can be derived from the diagnosis currently named as the basis for the regulation.\",\n",
        "  \"According to the service extracts from the health insurance, the insured has already been provided with the functional product requested according to its area of application.\",\n",
        "  \"A medically comprehensible explanation as to why the use of an orthopedic aid corresponding to the findings is not sufficient and instead electric foot lifter stimulation for walking would be more appropriate and therefore necessary has not been transmitted.\",\n",
        "  \"From an overall view of the information available here, it cannot be seen how the supply of the insured with the product could be justified, nor can the safety of such a supply be confirmed.\",\n",
        "  \"A medical justification for why a product not listed in the directory of aids should be used in the present case has not been transmitted.\"\n",
        "]"
      ],
      "metadata": {
        "id": "8mu2wI-9TVYU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_de = [\n",
        "  \"Bei der hier benannten Diagnose ist das Erfordernis eines Ausgleichs zur Sicherstellung des Grundbedürfnisses denkbar.\",\n",
        "  \"Die sozialmedizinischen Voraussetzungen für die verordnete Hilfsmittelversorgung sind erfüllt.\",\n",
        "  \"Alltagsrelevante Gebrauchsvorteile werden festgestellt.\",\n",
        "  \"Sozialmedizinische Indikation für das Hilfsmittel wird bestätigt.\",\n",
        "  \"Kontraindikationen wurden ausgeschlossen, es liegen keine Gegenanzeigen für die Verwendung des beantragten Hilfsmittels vor.\"\n",
        "]"
      ],
      "metadata": {
        "id": "PkFlXrwuuH_c"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_de = [\n",
        "  \"Aus der aktuell als verordnungsbegründend benannten Diagnose lässt sich kein konkreter Befund ableiten.\",\n",
        "  \"Gemäß den Leistungsauszügen der Krankenkasse ist der Versicherte bereits entsprechend dem Einsatzbereich des beantragten funktionellen Produkt versorgt.\",\n",
        "  \"Eine medizinisch nachvollziehbare Begründung, weshalb der Einsatz einer befundadäquaten orthopädietechnischen Hilfsmittelversorgung nicht ausreichend und stattdessen eine elektrische Fußheberstimulation zum Gehen zweckmäßiger und deshalb notwendig wäre, wurde nicht übermittelt.\",\n",
        "  \"In der Gesamtschau der hier vorliegenden Informationen kann nicht erkannt werden, wie die Versorgung des Versicherten mit dem Produkt begründet werden könnte, noch kann die Unbedenklichkeit einer solchen Versorgung bestätigt werden.\",\n",
        "  \"Eine ärztliche Begründung, warum im vorliegenden Fall ein nicht im Hilfsmittelverzeichnis gelistetes Produkt zum Einsatz kommen soll, wird nicht übermittelt.\"\n",
        "]"
      ],
      "metadata": {
        "id": "K2D3Y5K1uJpp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if lang == \"de\":\n",
        "  negative = negative_de\n",
        "  positive = positive_de\n",
        "else:\n",
        "  negative = negative_en\n",
        "  positive = positive_en"
      ],
      "metadata": {
        "id": "8Mg3YZG2t-Iq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Samples"
      ],
      "metadata": {
        "id": "aCGncKAR_OOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 15\n",
        "\n",
        "lang == \"de\" if index < 10 else \"en\"\n",
        "lang"
      ],
      "metadata": {
        "id": "rj7g7ECc_Kpx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "445b4607-e8d6-41db-effb-d1caa78a85fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_gt = df_results[[\"Ground_Truth\"]].iloc[index].values[0]\n",
        "sample_gt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uWhUpKXnwpn9",
        "outputId": "acce83b2-a596-4ba7-e88c-753b20fc587b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, a positive recommendation is given. The assessment acknowledges the necessity for compensation to meet basic needs, indicating a positive stance towards providing support.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_answer_model = \"results-Phi-3.5-MoE_4bit_en\" if lang == \"en\" else \"Phi-3.5-MoE_4bit_de\"\n",
        "sample_answer_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-ICWLGU6NLwc",
        "outputId": "275a44b6-7d1a-4cb9-bed2-ea67ebbacb2f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'results-Phi-3.5-MoE_4bit_en'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_answer = df_results[[sample_answer_model]].iloc[index].values[0]\n",
        "sample_answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Udk-QaL6M--7",
        "outputId": "05c404ff-2948-4d08-f622-09b34207bada"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, a positive recommendation is given. Justification: The assessment acknowledges the conceivable need for compensation to meet basic needs, indicating a positive stance towards providing support.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_context = df_results[[\"assessment\"]].iloc[index].values[0]\n",
        "sample_context"
      ],
      "metadata": {
        "id": "VKWOI50J_HES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce431549-cf26-4d40-cf52-44e0ca238fce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'With the diagnosis named here, the need for compensation to ensure the basic need is conceivable.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_question = question_en if lang == \"en\" else question_de\n",
        "sample_question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "utieLfaGKmWA",
        "outputId": "8ec9a700-a843-4868-fd46-3725950cb9ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWhat is the result of the assessment? \\nIs a positive or negative recommendation given? \\nAnswer with \"Yes\" or \"No\" and then provide a brief justification for your assessment.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria"
      ],
      "metadata": {
        "id": "o_8dOmMpjt0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PII on all contexts\n",
        "\n",
        "Prompt adapted from: https://www.evidentlyai.com/blog/open-source-llm-evaluation#llm-as-a-judge"
      ],
      "metadata": {
        "id": "OgOnGInRjx4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\\n\".join(positive + negative)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNCI_OXbDnck",
        "outputId": "f6b87dfe-5275-455f-f3d3-a9e7c46205fd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With the diagnosis named here, the need for compensation to ensure the basic need is conceivable.\n",
            "The socio-medical prerequisites for the prescribed aid supply have been met.\n",
            "Everyday relevant usage benefits have been determined.\n",
            "Socio-medical indication for the aid is confirmed.\n",
            "Contraindications have been excluded; there are no contraindications for the use of the requested aid.\n",
            "No specific findings can be derived from the diagnosis currently named as the basis for the regulation.\n",
            "According to the service extracts from the health insurance, the insured has already been provided with the functional product requested according to its area of application.\n",
            "A medically comprehensible explanation as to why the use of an orthopedic aid corresponding to the findings is not sufficient and instead electric foot lifter stimulation for walking would be more appropriate and therefore necessary has not been transmitted.\n",
            "From an overall view of the information available here, it cannot be seen how the supply of the insured with the product could be justified, nor can the safety of such a supply be confirmed.\n",
            "A medical justification for why a product not listed in the directory of aids should be used in the present case has not been transmitted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"Oliver Zeigermann, geboren 22.12.1890 in Hamburg\"\n",
        "# text = \"geboren 22.12.1890 in Hamburg\"\n",
        "# text = \"aus Hamburg-Ottensen\""
      ],
      "metadata": {
        "id": "-F-PTDuvGeT5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = '''\n",
        "Personally identifiable information (PII) is information that, when used alone or with other relevant data, can identify an individual.\n",
        "\n",
        "PII could be a person's name or address or date or location of birth or telephone number or social security number or something similar.\n",
        "\n",
        "Be strict, even a PII identifier may be enough.\n",
        "'''\n",
        "\n",
        "pii_criteria = Criteria(\"PII Violation\", criteria, model, tokenizer, is_negative=True)\n",
        "pii_criteria.measure(TestCase(context=text))\n"
      ],
      "metadata": {
        "id": "qsSAKyOtAwtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2caa25-e213-4cf3-8a62-31d03b1004b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(name='PII Violation', score=1.0, reasoning='The provided conversation does not contain any personally identifiable information (PII) as defined. There are no mentions of names, addresses, dates of birth, telephone numbers, or social security numbers. The discussion focuses on medical and insurance-related matters without disclosing any PII.')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conciseness"
      ],
      "metadata": {
        "id": "18WFw_nLqTMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = \"\"\"\n",
        "Is the response brief and to the point, while still providing all necessary information.\n",
        "\"\"\"\n",
        "\n",
        "sample_case = TestCase(input=sample_question, output=sample_answer)\n",
        "conciseness_criteria = Criteria(\"Conciseness\", criteria, model, tokenizer)\n",
        "conciseness_criteria.measure(sample_case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvWT3W6CqSB7",
        "outputId": "1b69231f-6cbb-416e-e90a-58c2b50af5c3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(name='Conciseness', score=1.0, reasoning=\"The response is succinct, directly answering the question with a clear 'Yes' and a concise justification.\")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relevance"
      ],
      "metadata": {
        "id": "F2PubzUQqoJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = \"\"\"\n",
        "Does the given response directly address the question and effectively meets the question's intent?\n",
        "\"\"\"\n",
        "relevance_criteria = Criteria(\"Relevance\", criteria, model, tokenizer)\n",
        "\n",
        "sample_case = TestCase(input=sample_question, output=sample_answer)\n",
        "relevance_criteria.measure(sample_case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd20iJxqqp6m",
        "outputId": "35d7fb42-2536-421a-a3cb-ba674c86787b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(name='Relevance', score=1.0, reasoning=\"The response directly addresses the question by affirming a positive recommendation and provides a brief justification, indicating that the assessment meets the question's intent.\")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hallucination"
      ],
      "metadata": {
        "id": "I_mB0D7a-8iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = \"\"\"\n",
        "Do you see facts in the reponse that are not supported by the context?\n",
        "\"\"\"\n",
        "hallucinaton_criteria = Criteria(\"Hallucinaton\", criteria, model, tokenizer, is_negative=True)\n",
        "\n",
        "sample_case = TestCase(output=sample_answer, context=sample_context)\n",
        "hallucinaton_criteria.measure(sample_case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b14a87e-72b4-4c47-cfe7-017d8ae48dcc",
        "id": "CsnD9pHP-8iw"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(name='Hallucinaton', score=1.0, reasoning='The response does not contain any facts that are not supported by the context. The reasoning provided is based on the context given, which discusses the need for compensation to ensure basic needs. There are no unsupported facts or assertions made in the response.')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Suite"
      ],
      "metadata": {
        "id": "dS_V78nDMWeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestSuite:\n",
        "  def __init__(self, model, tokenizer, criteria: list[Criteria]):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.criteria = criteria\n",
        "\n",
        "  def measure(self, arguments: TestCase) -> list[Evaluation]:\n",
        "    evaluations = []\n",
        "    for criteria in self.criteria:\n",
        "      evaluations.append(criteria.measure(arguments))\n",
        "    average_score = sum([evaluation.score for evaluation in evaluations]) / len(evaluations)\n",
        "    evaluations.append(Evaluation(name=\"Average\", score=average_score, reasoning=\"\"))\n",
        "    return evaluations\n",
        "\n"
      ],
      "metadata": {
        "id": "TuDTYAtyMXT_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite = TestSuite(model, tokenizer, [conciseness_criteria, relevance_criteria, hallucinaton_criteria])\n",
        "sample_case = TestCase(input=sample_question, output=sample_answer, context=sample_context, expected_output=sample_gt)\n",
        "suite.measure(sample_case)"
      ],
      "metadata": {
        "id": "zvE7wbpmMpw-",
        "outputId": "8d137c6e-3c8a-4094-f58e-46c8ae316d67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Evaluation(name='Conciseness', score=1.0, reasoning=\"The response is succinct, directly answering the question with a clear 'Yes' and a brief justification, adhering to the criteria of being concise yet informative.\"),\n",
              " Evaluation(name='Relevance', score=1.0, reasoning=\"The response directly addresses the question by confirming a positive recommendation and justifies it by explaining the assessment's acknowledgment of the need for compensation to meet basic needs.\"),\n",
              " Evaluation(name='Hallucinaton', score=1.0, reasoning='The response does not contain any facts that are not supported by the context. The assessment is based on the provided context regarding the need for compensation to ensure basic needs, and the positive recommendation is justified within this context.'),\n",
              " Evaluation(name='Average', score=1.0, reasoning='')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(df_results)):\n",
        "  print(index)\n",
        "  lang = \"de\" if index < 10 else \"en\"\n",
        "  sample_gt = df_results[[\"Ground_Truth\"]].iloc[index].values[0]\n",
        "  sample_answer_model = \"results-Phi-3.5-MoE_4bit_en\" if lang == \"en\" else \"Phi-3.5-MoE_4bit_de\"\n",
        "  sample_answer = df_results[[sample_answer_model]].iloc[index].values[0]\n",
        "  sample_context = df_results[[\"assessment\"]].iloc[index].values[0]\n",
        "  sample_question = question_en if lang == \"en\" else question_de\n",
        "  assert sample_gt is not None\n",
        "  assert sample_answer is not None\n",
        "  assert sample_context is not None\n",
        "  assert sample_question is not None\n",
        "\n",
        "  print(f\"{sample_context}: {sample_answer}\")\n",
        "\n",
        "  sample_case = TestCase(input=sample_question, output=sample_answer, context=sample_context, expected_output=sample_gt)\n",
        "  evaluations: list[Evaluation] = suite.measure(sample_case)\n",
        "  for evaluation in evaluations:\n",
        "    print(f\"{evaluation.name}: {evaluation.score}\")\n",
        "    print(evaluation.reasoning)\n",
        "    print()\n",
        "  print(\"---\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Jyc6iqEzP4G1",
        "outputId": "e8baa006-5039-4ea8-b183-897e6298125f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Aus der aktuell als verordnungsbegründend benannten Diagnose lässt sich kein konkreter Befund ableiten.: Nein, es wird keine positive Empfehlung gegeben. Die Begründung ist, dass keine konkrete Diagnose vorliegt, die eine verordnungsbegründende Behandlung rechtfertigt.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert die notwendigen Informationen zur Bewertung der Diagnose ohne unnötige Details.\n",
            "\n",
            "Relevance: 0.0\n",
            "Die Antwort beantwortet nicht direkt die Frage nach einer Empfehlung, da keine konkreten Befunde aus der Diagnose vorhanden sind, um eine fundierte Empfehlung abzugeben.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine unbelegte Fakten; stattdessen wird auf die fehlende konkrete Diagnose und deren Auswirkungen auf eine verordnungsbegründende Bewertung hingewiesen.\n",
            "\n",
            "Average: 0.6666666666666666\n",
            "\n",
            "\n",
            "---\n",
            "1\n",
            "Gemäß den Leistungsauszügen der Krankenkasse ist der Versicherte bereits entsprechend dem Einsatzbereich des beantragten funktionellen Produkt versorgt.: Nein, es wird keine positive Empfehlung gegeben. Die Begründung ist, dass der Versicherte bereits entsprechend dem Einsatzbereich des beantragten funktionellen Produkts versorgt ist.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert alle notwendigen Informationen, da sie direkt auf die vorhandene Versorgung durch die Krankenkasse eingeht.\n",
            "\n",
            "Relevance: 0.0\n",
            "Die Antwort beantwortet nicht direkt die Frage nach einer Empfehlung. Stattdessen wird lediglich erwähnt, dass der Versicherte bereits entsprechend versorgt ist, was die Notwendigkeit einer weiteren Empfehlung negiert.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine unzutreffenden Fakten; sie ist durch den Kontext untermauert, der besagt, dass der Versicherte bereits entsprechend dem Einsatzbereich des beantragten funktionellen Produkts versorgt ist.\n",
            "\n",
            "Average: 0.6666666666666666\n",
            "\n",
            "\n",
            "---\n",
            "2\n",
            "Eine medizinisch nachvollziehbare Begründung, weshalb der Einsatz einer befundadäquaten orthopädietechnischen Hilfsmittelversorgung nicht ausreichend und stattdessen eine elektrische Fußheberstimulation zum Gehen zweckmäßiger und deshalb notwendig wäre, wurde nicht übermittelt.: Nein, es wird keine positive Empfehlung gegeben. Die Begründung liegt darin, dass keine medizinisch nachvollziehbare Begründung für den Einsatz einer elektrischen Fußheberstimulation vorliegt.\n",
            "Conciseness: 0.0\n",
            "Keine medizinisch nachvollziehbare Begründung für die Notwendigkeit einer elektrischen Fußheberstimulation vorhanden, daher keine positive Empfehlung.\n",
            "\n",
            "Relevance: 0.0\n",
            "Die Antwort fehlt eine medizinisch nachvollziehbare Begründung für die Notwendigkeit einer elektrischen Fußheberstimulation, und daher wird keine positive Empfehlung gegeben.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Keine medizinisch nachvollziehbare Begründung für die Notwendigkeit einer elektrischen Fußheberstimulation vorhanden, daher fehlt die Unterstützung durch den Kontext.\n",
            "\n",
            "Average: 0.3333333333333333\n",
            "\n",
            "\n",
            "---\n",
            "3\n",
            "In der Gesamtschau der hier vorliegenden Informationen kann nicht erkannt werden, wie die Versorgung des Versicherten mit dem Produkt begründet werden könnte, noch kann die Unbedenklichkeit einer solchen Versorgung bestätigt werden.: Nein, es wird keine positive Empfehlung gegeben. Die Begründung ist, dass die Versorgung des Versicherten mit dem Produkt nicht begründet und dessen Unbedenklichkeit nicht bestätigt werden kann.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert die notwendigen Informationen zur Bewertung der Konzisenz.\n",
            "\n",
            "Relevance: 0.0\n",
            "Die Antwort ignoriert die Frage nach dem Ergebnis der Bewertung und einer positiven oder negativen Empfehlung. Es fehlt eine direkte Antwort auf die gestellte Frage.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine unbelegte Fakten, sondern kritisiert die fehlende Begründung und Bestätigung der Versorgung im Kontext.\n",
            "\n",
            "Average: 0.6666666666666666\n",
            "\n",
            "\n",
            "---\n",
            "4\n",
            "Eine ärztliche Begründung, warum im vorliegenden Fall ein nicht im Hilfsmittelverzeichnis gelistetes Produkt zum Einsatz kommen soll, wird nicht übermittelt.: Nein, es wird keine positive Empfehlung gegeben. Die Begründung liegt in der fehlenden ärztlichen Begründung für den Einsatz eines nicht gelisteten Hilfsmittels.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert die notwendigen Informationen, da sie direkt auf die fehlende ärztliche Begründung eingeht, die für eine positive Empfehlung erforderlich ist.\n",
            "\n",
            "Relevance: 0.0\n",
            "Die Antwort ignoriert das Hauptanliegen, eine ärztliche Begründung für den Einsatz eines nicht im Hilfsmittelverzeichnis gelisteten Produkts bereitzustellen, was für eine positive Empfehlung notwendig ist.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine Fakten, die im Kontext unterstützt werden, da keine ärztliche Begründung für den Einsatz eines nicht im Hilfsmittelverzeichnis gelisteten Produkts vorhanden ist.\n",
            "\n",
            "Average: 0.6666666666666666\n",
            "\n",
            "\n",
            "---\n",
            "5\n",
            "Bei der hier benannten Diagnose ist das Erfordernis eines Ausgleichs zur Sicherstellung des Grundbedürfnisses denkbar.: Nein, es wird keine klare positive oder negative Empfehlung ausgesprochen. Die Begründung für die Einschätzung ist, dass lediglich die Möglichkeit eines Ausgleichs zur Sicherstellung des Grundbedürfnisses erwähnt wird, ohne eine klare Empfehlung für oder gegen eine Maßnahme zu geben.\n",
            "Conciseness: 0.5\n",
            "Die Antwort ist prägnant, aber fehlt eine klare Empfehlung, wodurch die Kriterien der Konzisenz nicht vollständig erfüllt werden.\n",
            "\n",
            "Relevance: 0.5\n",
            "Die Antwort erwähnt die Notwendigkeit eines Ausgleichs zur Sicherstellung des Grundbedürfnisses, was relevant ist, aber keine klare Empfehlung für oder gegen eine Maßnahme gibt, daher ist sie nur teilweise relevant.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine unbelegte Fakten und ist vollständig im Kontext des gegebenen Dialogs begründet. Es gibt keine Hinweise auf Unstimmigkeiten oder unbelegte Informationen.\n",
            "\n",
            "Average: 0.6666666666666666\n",
            "\n",
            "\n",
            "---\n",
            "6\n",
            "Die sozialmedizinischen Voraussetzungen für die verordnete Hilfsmittelversorgung sind erfüllt.: Ja, es wird eine positive Empfehlung gegeben. Die sozialmedizinischen Voraussetzungen für die verordnete Hilfsmittelversorgung sind erfüllt.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert alle notwendigen Informationen zur Erfüllung der sozialmedizinischen Voraussetzungen für die Hilfsmittelversorgung.\n",
            "\n",
            "Relevance: 1.0\n",
            "Die Antwort beantwortet direkt die Frage nach der Erfüllung der sozialmedizinischen Voraussetzungen für die Hilfsmittelversorgung und stellt somit eine positive Empfehlung dar.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine unbelegte Fakten; sie basiert auf den gegebenen sozialmedizinischen Voraussetzungen für die Hilfsmittelversorgung.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "7\n",
            "Alltagsrelevante Gebrauchsvorteile werden festgestellt.: Ja, es wird eine positive Empfehlung gegeben. Die Feststellung alltagsrelevanter Gebrauchsvorteile impliziert, dass der Versicherte von dem bewerteten Produkt oder Service profitiert.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert die notwendigen Informationen zur positiven Empfehlung aufgrund der Feststellung alltagsrelevanter Gebrauchsvorteile.\n",
            "\n",
            "Relevance: 1.0\n",
            "Die Antwort beantwortet direkt die Frage nach der Empfehlung und zeigt, dass alltagsrelevante Gebrauchsvorteile festgestellt wurden, was auf eine positive Bewertung hinweist.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine Fakten, die nicht durch den Kontext unterstützt werden. Stattdessen wird eine positive Bewertung aufgrund der Feststellung alltagsrelevanter Gebrauchsvorteile gegeben, was im Kontext begründet ist.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "8\n",
            "Sozialmedizinische Indikation für das Hilfsmittel wird bestätigt.: Ja, es wird eine positive Empfehlung gegeben. Die sozialmedizinische Indikation für das Hilfsmittel wird bestätigt, was bedeutet, dass die medizinische Notwendigkeit für das Hilfsmittel anerkannt wurde.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert alle notwendigen Informationen zur Bestätigung der sozialmedizinischen Indikation für das Hilfsmittel.\n",
            "\n",
            "Relevance: 1.0\n",
            "Die Antwort bestätigt die sozialmedizinische Indikation für das Hilfsmittel, was direkt auf die Frage nach der Empfehlung und deren positivem oder negativen Ausgang eingeht.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "Die Antwort enthält keine unzulänglichen oder nicht unterstützten Fakten; sie basiert auf der gegebenen Kontextinformation, dass die sozialmedizinische Indikation für das Hilfsmittel bestätigt wurde.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "9\n",
            "Kontraindikationen wurden ausgeschlossen, es liegen keine Gegenanzeigen für die Verwendung des beantragten Hilfsmittels vor.: Ja, es wird eine positive Empfehlung gegeben. Die Begründung ist, dass keine Kontraindikationen oder Gegenanzeigen vorliegen.\n",
            "Conciseness: 1.0\n",
            "Die Antwort ist prägnant und liefert alle notwendigen Informationen, da keine zusätzlichen Details notwendig sind und die Abwesenheit von Kontraindikationen eine positive Bewertung unterstützt.\n",
            "\n",
            "Relevance: 1.0\n",
            "Die Antwort beantwortet die Frage direkt und bestätigt, dass keine Kontraindikationen vorliegen, was eine positive Empfehlung für die Verwendung des Hilfsmittels impliziert.\n",
            "\n",
            "Hallucinaton: 0.0\n",
            "Die Antwort ist durch den Kontext untermauert, da keine unstützten Fakten vorhanden sind und keine Kontraindikationen oder Gegenanzeigen erwähnt werden.\n",
            "\n",
            "Average: 0.6666666666666666\n",
            "\n",
            "\n",
            "---\n",
            "10\n",
            "No specific findings can be derived from the diagnosis currently named as the basis for the regulation.: No, a positive recommendation is not given. Justification: The assessment indicates a lack of sufficient evidence from the diagnosis to support a regulatory decision.\n",
            "Conciseness: 1.0\n",
            "The response is succinct, directly answering the question with a 'No' and a clear justification, adhering to the criteria of being brief and informative.\n",
            "\n",
            "Relevance: 1.0\n",
            "The response directly addresses the question by stating that a positive recommendation is not given due to insufficient evidence from the diagnosis, which aligns with the question's intent to understand the outcome of the assessment.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The assessment is based on the provided context, which lacks specific findings to support a positive recommendation.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "11\n",
            "According to the service extracts from the health insurance, the insured has already been provided with the functional product requested according to its area of application.: Yes, a positive recommendation is given. Justification: The insured has received the requested functional product within its area of application, indicating compliance with the service provision. Yes, a positive recommendation is given. Justification: The provision of the requested functional product to the insured within its designated area of application demonstrates adherence to the required service standards. Yes, a positive recommendation is given. Justification: The insured's receipt of the requested functional product within its specified area of application signifies compliance with the service provision requirements.\n",
            "\n",
            "In summary, a positive recommendation is given based on the insured's receipt of the requested functional product within its designated area of application, demonstrating compliance with the required service standards.\n",
            "\n",
            "Please note that this assessment is based on the provided information and may be subject to further review or clarification as needed.\n",
            "\n",
            "I hope this response is helpful. If you have any further questions or require additional information, please do not hesitate to ask.\n",
            "\n",
            "Thank you for your attention to this matter.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "\n",
            "[Your Title/Position]\n",
            "\n",
            "[Your Contact Information] Yes, a positive recommendation is given. Justification: The insured has received the requested functional product within its designated area of application, demonstrating compliance with the required service standards.\n",
            "\n",
            "In summary, a positive recommendation is given based on the insured's receipt of the requested functional product within its designated area of application, demonstrating compliance with the required service standards.\n",
            "\n",
            "Please note that this assessment is based on the provided information and may be subject to further review or clarification as needed.\n",
            "\n",
            "I hope this response is helpful. If you have any further questions or require additional information, please do not hesitate to ask.\n",
            "\n",
            "Thank you for your attention to this matter.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "\n",
            "[Your Title/Position]\n",
            "\n",
            "[Your Contact Information] Yes, a positive recommendation is given. Justification: The insured has received the requested functional product within its designated area of application, demonstrating compliance with the required service standards.\n",
            "\n",
            "In summary, a positive recommendation is given based on the insured's receipt of the requested functional product within its designated area of application, demonstrating compliance with the required service standards.\n",
            "\n",
            "Please note that this assess\n",
            "Conciseness: 1.0\n",
            "The response provided is concise, directly addressing the question with a clear 'Yes' and a brief justification. It avoids unnecessary details, adhering to the criterion of being brief and to the point.\n",
            "\n",
            "Relevance: 0.5\n",
            "The response acknowledges that the insured has received the functional product, which is relevant to the question about the assessment result. However, it does not explicitly state whether this leads to a positive or negative recommendation, which is a key aspect of the question's intent. Therefore, the response is partially relevant but lacks a clear connection to the recommendation outcome.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The provided information confirms that the insured has received the requested functional product within its designated area of application, which aligns with the context. There are no unsupported facts or misinformation present in the response.\n",
            "\n",
            "Average: 0.8333333333333334\n",
            "\n",
            "\n",
            "---\n",
            "12\n",
            "A medically comprehensible explanation as to why the use of an orthopedic aid corresponding to the findings is not sufficient and instead electric foot lifter stimulation for walking would be more appropriate and therefore necessary has not been transmitted.: No, a positive recommendation is not given. The assessment indicates that the provided justification for the electric foot lifter stimulation is insufficient and lacks medical clarity.\n",
            "Conciseness: 0.0\n",
            "The response lacks brevity and fails to concisely justify the necessity of electric foot lifter stimulation, missing essential medical clarity.\n",
            "\n",
            "Relevance: 0.0\n",
            "The response does not directly address the question regarding the result of the assessment and the nature of the recommendation. It lacks a clear justification for the necessity of electric foot lifter stimulation and fails to provide a medically comprehensible explanation.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any unsupported facts; however, it fails to provide a medically comprehensible explanation for the necessity of electric foot lifter stimulation, which is required by the context.\n",
            "\n",
            "Average: 0.3333333333333333\n",
            "\n",
            "\n",
            "---\n",
            "13\n",
            "From an overall view of the information available here, it cannot be seen how the supply of the insured with the product could be justified, nor can the safety of such a supply be confirmed.: No, a positive recommendation is not given. The justification is that the supply of the insured product cannot be justified, nor can its safety be confirmed.\n",
            "Conciseness: 1.0\n",
            "The response is succinct, directly addressing the question with a clear 'No' and a brief justification, which meets the criteria for conciseness.\n",
            "\n",
            "Relevance: 1.0\n",
            "The response directly addresses the question by stating that a positive recommendation is not given due to the lack of justification for the supply and confirmation of safety, which aligns with the question's intent to understand the result of the assessment.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The assessment is based on the provided context, which does not contain any unsupported facts.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "14\n",
            "A medical justification for why a product not listed in the directory of aids should be used in the present case has not been transmitted.: No, a positive recommendation is not given. Justification: Lack of medical justification for the use of a non-listed aid.\n",
            "Conciseness: 1.0\n",
            "The response is succinct, directly addressing the lack of medical justification and the necessity for it to issue a positive recommendation.\n",
            "\n",
            "Relevance: 0.0\n",
            "The response does not directly address the question regarding the result of the assessment or provide a positive recommendation. It lacks a clear justification for the assessment outcome.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The assessment is based on the provided context and question, and the answer is directly related to the lack of medical justification for the use of a non-listed aid.\n",
            "\n",
            "Average: 0.6666666666666666\n",
            "\n",
            "\n",
            "---\n",
            "15\n",
            "With the diagnosis named here, the need for compensation to ensure the basic need is conceivable.: Yes, a positive recommendation is given. Justification: The assessment acknowledges the conceivable need for compensation to meet basic needs, indicating a positive stance towards providing support.\n",
            "Conciseness: 1.0\n",
            "The response is succinct, directly answering the question with a clear 'Yes' and a brief justification, adhering to the criteria of being concise yet informative.\n",
            "\n",
            "Relevance: 1.0\n",
            "The response directly addresses the question by confirming a positive recommendation and justifies it by explaining the assessment's acknowledgment of the need for compensation to meet basic needs.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The assessment is based on the provided context regarding the need for compensation to ensure basic needs, and the positive recommendation is justified within this context.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "16\n",
            "The socio-medical prerequisites for the prescribed aid supply have been met.: Yes, a positive recommendation is given. The assessment confirms that the socio-medical prerequisites for the prescribed aid supply have been met.\n",
            "Conciseness: 1.0\n",
            "The response is succinct, providing a clear 'Yes' with a brief justification that directly relates to the assessment of the socio-medical prerequisites being met.\n",
            "\n",
            "Relevance: 1.0\n",
            "The response directly addresses the question by confirming that the socio-medical prerequisites for the prescribed aid supply have been met, which aligns with the question's intent to understand the result of the assessment and the nature of the recommendation.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The answer is based on the provided context, which states that the socio-medical prerequisites for the prescribed aid supply have been met, leading to a positive recommendation.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "17\n",
            "Everyday relevant usage benefits have been determined.: Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given. Justification: The assessment explicitly states that \"everyday relevant usage benefits\" have been determined, indicating a favorable outcome. Yes, a positive recommendation is given.\n",
            "Conciseness: 1.0\n",
            "The response is succinct and directly addresses the question with a clear justification, meeting the criteria for conciseness.\n",
            "\n",
            "Relevance: 1.0\n",
            "The response directly addresses the question by confirming the determination of everyday relevant usage benefits, which aligns with the question's intent to understand the result of the assessment and whether a positive recommendation is given.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The context provided discusses the determination of everyday relevant usage benefits, which is directly supported by the response. Therefore, there is no hallucination present in the response.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "18\n",
            "Socio-medical indication for the aid is confirmed.: Yes, a positive recommendation is given. The socio-medical indication for the aid is confirmed, which implies that the assessment supports the provision of aid.\n",
            "Conciseness: 1.0\n",
            "The response provided a clear and direct answer, confirming a positive recommendation with a brief justification based on the socio-medical indication for aid.\n",
            "\n",
            "Relevance: 1.0\n",
            "The response directly addresses the question by confirming a positive recommendation based on the socio-medical indication for aid, which aligns with the question's intent to understand the outcome of the assessment.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The answer provided is directly related to the confirmed socio-medical indication for the aid, which is the only context given.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n",
            "19\n",
            "Contraindications have been excluded; there are no contraindications for the use of the requested aid.: Yes, a positive recommendation is given. Justification: Contraindications have been excluded, indicating that the use of the requested aid is appropriate.\n",
            "Conciseness: 1.0\n",
            "The response is succinct, clearly stating the positive recommendation and the reason for it, which is the absence of contraindications.\n",
            "\n",
            "Relevance: 1.0\n",
            "The response directly addresses the question by confirming the absence of contraindications and justifies a positive recommendation for the use of the requested aid.\n",
            "\n",
            "Hallucinaton: 1.0\n",
            "The response does not contain any facts that are not supported by the context. The context clearly states that contraindications have been excluded, which supports the positive recommendation for the use of the requested aid.\n",
            "\n",
            "Average: 1.0\n",
            "\n",
            "\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final inspection of memory, how much did the context window eat up\n",
        "\n",
        "* not to be confused with the assessment context\n",
        "* this is technical\n",
        "* composed of everything that is sent to the LLM inclusing system prompt, /  input question and assessment context\n",
        "\n",
        "Phi models take a lot of memory with growing context, Llama much more modest\n"
      ],
      "metadata": {
        "id": "jUUveM-Ej2Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOf_Fv1PELPp",
        "outputId": "80f06d85-7a64-4171-a581-ec18ff7ef7c9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 25 11:50:00 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   78C    P0              73W /  70W |   8913MiB / 15360MiB |     45%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9rfwWPPKMOY"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}